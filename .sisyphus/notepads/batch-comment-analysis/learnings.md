# 批次评论分析优化 - 学习记录

## 完成日期
2026-02-02

## 核心问题
AI 评论分析每条评论一个请求，导致：
- 500 条评论 = 500 次 API 请求
- 每次重复发送 1000+ 字符的 system_prompt
- 耗时 5-10 分钟

## 解决方案
将多条评论合并到一个 API 请求中，通过动态批次策略控制字符数。

## 关键设计决策

### 1. 批次大小计算
- 可用 tokens: 4000 (保守估计)
- System Prompt: 1000 tokens
- 预留输出: 1500 tokens
- 可用输入: ~1500 tokens ≈ 1000 中文字符
- **最终选择**: 3000 字符/批，最多 15 条

### 2. 动态分批策略
按字符数而非固定条数分批：
- 长评论自动单独成批
- 短评论合并处理
- 视频标题计入字符数

### 3. 降级机制
批量分析失败时，自动回退到原有的并发单条分析。

## 代码结构

### 新增文件
- `backend/ai/batch.go` - 批次计算模块
- `backend/ai/batch_test.go` - 单元测试

### 修改文件
- `backend/ai/analysis.go`:
  - 新增 `BatchAnalysisResult` 类型
  - 新增 `AnalyzeCommentsBatchMerged` 函数
  - 修改 `AnalyzeCommentsWithRateLimit` 使用新的批量分析

## 性能预期

| 指标 | 优化前 | 优化后 |
|------|--------|--------|
| 500 条评论 API 调用 | 500 次 | ~35 次 |
| 分析耗时 | 5-10 分钟 | 1-2 分钟 |
| Token 消耗 | 高 | 降低 80%+ |

## 测试验证
- ✅ TestCalculateBatches - 5 个子测试全部通过
- ✅ TestCalculateBatchesWithVideoTitle - 视频标题计入字符数
- ✅ TestDefaultBatchConfig - 默认配置测试
- ✅ go build ./backend/... - 编译通过

## 注意事项
1. 批次大小需要根据实际 AI 模型调整
2. 超长评论（>3000 字符）会自动单独成批
3. 保留了原有的单条分析作为降级方案
4. 需要监控批量分析的准确率

## 后续优化方向
1. 根据实际运行数据调整批次大小
2. 添加批量分析成功率监控
3. 考虑实现自适应批次大小（根据评论长度动态调整）
